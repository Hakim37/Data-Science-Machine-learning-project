{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d7d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa3ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2d465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available combinations :  [(0.1, 100), (0.1, 200), (0.1, 300), (0.1, 400), (0.1, 500), (0.2, 100), (0.2, 200), (0.2, 300), (0.2, 400), (0.2, 500), (0.3, 100), (0.3, 200), (0.3, 300), (0.3, 400), (0.3, 500), (0.4, 100), (0.4, 200), (0.4, 300), (0.4, 400), (0.4, 500), (0.5, 100), (0.5, 200), (0.5, 300), (0.5, 400), (0.5, 500), (0.01, 100), (0.01, 200), (0.01, 300), (0.01, 400), (0.01, 500), (0.02, 100), (0.02, 200), (0.02, 300), (0.02, 400), (0.02, 500), (0.03, 100), (0.03, 200), (0.03, 300), (0.03, 400), (0.03, 500), (0.04, 100), (0.04, 200), (0.04, 300), (0.04, 400), (0.04, 500), (0.05, 100), (0.05, 200), (0.05, 300), (0.05, 400), (0.05, 500)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6a5e2da2395e>:25: RuntimeWarning: overflow encountered in exp\n",
      "  A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
      "<ipython-input-3-6a5e2da2395e>:40: RuntimeWarning: overflow encountered in exp\n",
      "  Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy achieved by our model through grid searching :  71.76470588235294\n"
     ]
    }
   ],
   "source": [
    "# Grid Searching in Logistic Regression\n",
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training            \n",
    "    def fit( self, X, Y ) :        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        self.m, self.n = X.shape\n",
    "          \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning                \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent    \n",
    "    def update_weights( self ) :           \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db        \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x )     \n",
    "    def predict( self, X ) :    \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y\n",
    "        \n",
    "     \n",
    "# Driver code\n",
    "  \n",
    "def main() :\n",
    "      \n",
    "    # Importing dataset    \n",
    "    df = pd.read_csv( \"diabetes.csv\" )\n",
    "    X = df.iloc[:,:-1].values\n",
    "    Y = df.iloc[:,-1:].values\n",
    "      \n",
    "    # Splitting dataset into train and validation set\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split( \n",
    "      X, Y, test_size = 1/3, random_state = 0 )\n",
    "      \n",
    "    # Model training    \n",
    "    max_accuracy = 0\n",
    "      \n",
    "    # learning_rate choices    \n",
    "    learning_rates = [ 0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "                      0.01, 0.02, 0.03, 0.04, 0.05 ]\n",
    "      \n",
    "    # iterations choices    \n",
    "    iterations = [ 100, 200, 300, 400, 500 ]\n",
    "      \n",
    "    # available combination of learning_rate and iterations\n",
    "      \n",
    "    parameters = []    \n",
    "    for i in learning_rates :        \n",
    "        for j in iterations :            \n",
    "            parameters.append( ( i, j ) )\n",
    "              \n",
    "    print(\"Available combinations : \",  parameters )\n",
    "              \n",
    "    # Applying linear searching in list of available combination\n",
    "    # to achieved maximum accuracy on CV set\n",
    "      \n",
    "    for k in range( len( parameters ) ) :        \n",
    "        model = LogitRegression( learning_rate = parameters[k][0], \n",
    "                                iterations = parameters[k][1] )\n",
    "      \n",
    "        model.fit( X_train, Y_train )\n",
    "        \n",
    "        # Prediction on validation set\n",
    "        Y_pred = model.predict( X_valid )\n",
    "       \n",
    "        # measure performance on validation set\n",
    "      \n",
    "        correctly_classified = 0\n",
    "      \n",
    "        # counter    \n",
    "        count = 0\n",
    "      \n",
    "        for count in range( np.size( Y_pred ) ) :            \n",
    "            if Y_valid[count] == Y_pred[count] :                \n",
    "                correctly_classified = correctly_classified + 1   \n",
    "                  \n",
    "        curr_accuracy = ( correctly_classified / count ) * 100\n",
    "                  \n",
    "        if max_accuracy < curr_accuracy :            \n",
    "            max_accuracy = curr_accuracy\n",
    "              \n",
    "    print( \"Maximum accuracy achieved by our model through grid searching : \", max_accuracy )\n",
    "     \n",
    "if __name__ == \"__main__\" :     \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef645576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c74c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c77e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
